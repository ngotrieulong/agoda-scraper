{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63829caa",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport time\nimport json\nfrom dotenv import load_dotenv\nfrom playwright.async_api import async_playwright\nfrom agentql import wrap, configure\n\n\n\n# --- 1. T·∫£i Bi·∫øn M√¥i Tr∆∞·ªùng ---\nprint(\"INFO: ƒêang t·∫£i bi·∫øn m√¥i tr∆∞·ªùng t·ª´ .env...\")\nload_dotenv()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y credentials t·ª´ file .env\n",
    "AGENTQL_API_KEY = os.getenv(\"AGENTQL_API_KEY\")\n",
    "IDEALIST_EMAIL = os.getenv(\"IDEALIST_EMAIL\")\n",
    "IDEALIST_PASSWORD = os.getenv(\"IDEALIST_PASSWORD\")\n",
    "\n",
    "# C·∫•u h√¨nh AgentQL API Key\n",
    "if AGENTQL_API_KEY:\n",
    "    configure(api_key=AGENTQL_API_KEY)\n",
    "\n",
    "# --- 2. C·∫§U H√åNH CHUNG ---\n",
    "LOGIN_URL = \"https://www.idealist.org/en/\"\n",
    "JOB_SEARCH_URL = \"https://www.idealist.org/en/jobs\"\n",
    "SESSION_FILE = \"idealist_login.json\"\n",
    "RESULT_JSON_FILE = \"scraped_jobs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855546fb",
   "metadata": {},
   "outputs": [],
   "source": "# Kh·ªüi t·∫°o Playwright\n\nprint(\"--- üöÄ B·∫ÆT ƒê·∫¶U AGENTQL SCRAPER ---\")\njob_data_all_pages = []\nheadless=False         # False: Hi·ªán browser, True: ·∫®n browser\nMAX_JOBS_TO_CRAWL = 5  # S·ªë l∆∞·ª£ng jobs t·ªëi ƒëa c·∫ßn crawl\n# Query d·ªØ li·ªáu jobs\nJOB_POSTS_QUERY = \"\"\"\n{\n    job_posts[] {\n        org_name\n        job_title\n        salary (Optional)\n        location\n        contract_type (Optional)\n        location_type (Optional, \"remote or on-site or hybrid\")\n        date_posted (Optional)\n    }\n}\n\"\"\"\n\nPAGINATION_QUERY = \"\"\"\n{\n    pagination {\n        next_page_btn(Next page)\n    }\n}\n\"\"\"\n\n\n# --- 3. H√ÄM LOGIN & PASS CAPTCHA ü§ñ ---\nasync def login_and_save_session(page):\n    \"\"\"\n    Th·ª±c hi·ªán quy tr√¨nh login ph·ª©c t·∫°p v√† l∆∞u session state.\n    \"\"\"\n    print(\"INFO: üîë B·∫Øt ƒë·∫ßu qu√° tr√¨nh login m·ªõi...\")\n\n    # 1. ƒêi t·ªõi URL login\n    await page.goto(LOGIN_URL)\n\n    # 2. T√¨m √¥ email v√† n√∫t \"Continue\"\n    print(\"INFO: üß† [AgentQL] ƒêang t√¨m √¥ email...\")\n    EMAIL_QUERY = \"\"\"\n    {\n        login_form {\n            email_input\n            continue_button\n        }\n    }\n    \"\"\"\n    email_form = await page.query_elements(EMAIL_QUERY)\n\n    print(\"INFO: ü¶æ [Playwright] ƒêang g√µ email...\")\n    await email_form.login_form.email_input.fill(IDEALIST_EMAIL)\n\n    # 3. Click \"Continue\"\n    await email_form.login_form.continue_button.click()\n    print(\"INFO: ü¶æ [Playwright] ƒê√£ click Continue. Ch·ªù trang password...\")\n\n    # 4. Ch·ªù v√† x·ª≠ l√Ω CAPTCHA n·∫øu xu·∫•t hi·ªán\n    await asyncio.sleep(2)\n    print(\"INFO: ü§ñ Ki·ªÉm tra CAPTCHA...\")\n    print(\"INFO: ‚ö†Ô∏è  N·∫øu CAPTCHA xu·∫•t hi·ªán, vui l√≤ng gi·∫£i quy·∫øt th·ªß c√¥ng trong 120 gi√¢y...\")\n    print(\"INFO: ‚è≥ Script s·∫Ω t·ª± ƒë·ªông ti·∫øp t·ª•c sau khi b·∫°n gi·∫£i CAPTCHA...\")\n\n    # 5. Ch·ªù trang password load (timeout 120s cho CAPTCHA)\n    await page.wait_for_selector('input[type=\"password\"]', timeout=120000)\n    print(\"INFO: ‚úÖ CAPTCHA ƒë√£ ƒë∆∞·ª£c gi·∫£i quy·∫øt (ho·∫∑c kh√¥ng c√≥)!\")\n\n    # 6. T√¨m √¥ password v√† n√∫t \"Log in\"\n    print(\"INFO: üß† [AgentQL] ƒêang t√¨m √¥ password...\")\n    PASSWORD_QUERY = \"\"\"\n    {\n        password_form {\n            password_input\n            login_button(Log in)\n        }\n    }\n    \"\"\"\n    password_form = await page.query_elements(PASSWORD_QUERY)\n\n    print(\"INFO: ü¶æ [Playwright] ƒêang g√µ password...\")\n    await password_form.password_form.password_input.fill(IDEALIST_PASSWORD)\n\n    # 7. Click Login\n    await password_form.password_form.login_button.click()\n\n    # 8. Ch·ªù login th√†nh c√¥ng\n    print(\"INFO: ‚è≥ ƒêang ch·ªù login th√†nh c√¥ng...\")\n    await asyncio.sleep(3)\n\n    # Ki·ªÉm tra xem ƒë√£ login th√†nh c√¥ng ch∆∞a\n    for _ in range(20):\n        current_url = page.url\n        if \"login\" not in current_url:\n            print(f\"INFO: ‚úÖ Login th√†nh c√¥ng! ƒê√£ chuy·ªÉn t·ªõi: {current_url}\")\n            return\n        await asyncio.sleep(1)\n\n    # N·∫øu v·∫´n ·ªü trang login sau 20s\n    print(f\"WARNING: ‚ö†Ô∏è  V·∫´n ·ªü trang login. URL hi·ªán t·∫°i: {page.url}\")\n\n\n# --- 4. H√ÄM GHI JSON RA FILE ---\ndef write_json_file(job_data_all_pages: list, file_path: str):\n    \"\"\"Ghi danh s√°ch jobs ra file JSON.\"\"\"\n    try:\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(job_data_all_pages, f, ensure_ascii=False, indent=2)\n        print(f\"INFO: ‚úçÔ∏è  ƒê√£ ghi {len(job_data_all_pages)} jobs ra file {file_path}\")\n    except Exception as e:\n        print(f\"ERROR: ‚ùå Kh√¥ng th·ªÉ ghi file JSON: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be9268",
   "metadata": {},
   "outputs": [],
   "source": "# Kh·ªüi t·∫°o Playwright\nimport asyncio\n\nasync with async_playwright() as p:\n    browser = await p.chromium.launch(headless=headless, slow_mo=300 if not headless else 0)\n    context = None\n\n    # --- [Ki·ªÉm tra file session] ---\n    if os.path.exists(SESSION_FILE):\n        try:\n            print(f\"INFO: üîë ƒê√£ t√¨m th·∫•y file session ({SESSION_FILE}). ƒêang t·∫£i session...\")\n            context = await browser.new_context(storage_state=SESSION_FILE)\n            print(\"INFO: ‚úÖ T·∫£i session th√†nh c√¥ng. B·ªè qua login.\")\n        except Exception as e:\n            print(f\"ERROR: ‚ùå T·∫£i session th·∫•t b·∫°i: {e}. S·∫Ω login l·∫°i t·ª´ ƒë·∫ßu.\")\n            os.remove(SESSION_FILE)\n            context = None\n\n    # --- [Login n·∫øu ch∆∞a c√≥ session] ---\n    if not context:\n        context = await browser.new_context()\n        page_for_login = wrap(await context.new_page())\n\n        try:\n            await login_and_save_session(page_for_login)\n\n            # L∆∞u session state\n            await context.storage_state(path=SESSION_FILE)\n            print(f\"INFO: üîë ƒê√£ l∆∞u session state v√†o {SESSION_FILE}\")\n\n        except Exception as e:\n            print(f\"ERROR: ‚ùå Qu√° tr√¨nh login th·∫•t b·∫°i: {e}\")\n            await browser.close()\n            \n\n        finally:\n            await page_for_login.close()\n\n    # --- [Scrape Jobs] ---\n    page = wrap(await context.new_page())\n    print(f\"INFO: ü¶æ [Playwright] ƒêang ƒëi·ªÅu h∆∞·ªõng t·ªõi: {JOB_SEARCH_URL}\")\n    await page.goto(JOB_SEARCH_URL)\n    await asyncio.sleep(2)  # ƒê·ª£i trang load\n\n    # --- [While Loop - Scrape t·ª´ng trang] ---\n    page_count = 1\n    while True:\n        print(f\"\\n--- üîÑ ƒêang scrape trang {page_count} ---\")\n        print(\"INFO: üß† [AgentQL] ƒêang truy v·∫•n data c√°c job post...\")\n\n        try:\n            results = await page.query_data(JOB_POSTS_QUERY, timeout=15000)\n            job_list = results.get(\"job_posts\", [])\n            print(\"debug\", job_list)\n        except Exception as e:\n            print(f\"ERROR: ‚ùå L·ªói khi query data: {e}\")\n            break\n\n        # Th√™m jobs v√†o danh s√°ch t·ªïng\n        job_data_all_pages.extend(job_list)\n        print(f\"INFO: ‚úÖ T√¨m th·∫•y {len(job_list)} jobs tr√™n trang n√†y.\")\n        print(f\"INFO: üìä T·ªïng s·ªë jobs ƒë√£ scrape: {len(job_data_all_pages)}/{MAX_JOBS_TO_CRAWL}\")\n\n        # Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng\n        if len(job_list) == 0:\n            print(\"INFO: ü§∑ Kh√¥ng t√¨m th·∫•y job n√†o, c√≥ th·ªÉ ƒë√£ h·∫øt.\")\n            break\n\n        # L∆∞u sau m·ªói trang\n        write_json_file(job_data_all_pages, RESULT_JSON_FILE)\n\n        # T√¨m v√† click n√∫t \"Next page\"\n        print(\"INFO: üß† [AgentQL] ƒêang t√¨m n√∫t 'Next page'...\")\n        try:\n            pagination = await page.query_elements(PAGINATION_QUERY, timeout=5000)\n            print(\"INFO: ü¶æ [Playwright] ƒê√£ t√¨m th·∫•y! Click ƒë·ªÉ sang trang m·ªõi...\")\n            await pagination.pagination.next_page_btn.click()\n            await page.wait_for_load_state(\"networkidle\", timeout=20000)\n            page_count += 1\n            await asyncio.sleep(2)\n        except:\n            print(\"INFO: ‚úÖ Kh√¥ng t√¨m th·∫•y n√∫t 'Next page'. ƒê√£ scrape h·∫øt t·∫•t c·∫£ c√°c trang.\")\n            break\n        \n        if len(job_data_all_pages) >= MAX_JOBS_TO_CRAWL:\n            print(f\"INFO: üéØ ƒê√£ ƒë·ªß {MAX_JOBS_TO_CRAWL} jobs! D·ª´ng scraping.\")\n            break\n\n    # --- [K·∫æT TH√öC] ---\n    print(\"\\n--- ‚ú® QU√Å TR√åNH SCRAPE HO√ÄN T·∫§T ---\")\n    print(f\"INFO: üìà T·ªïng c·ªông ƒë√£ scrape: {len(job_data_all_pages)} jobs\")\n\n    # Ghi k·∫øt qu·∫£ cu·ªëi c√πng\n    write_json_file(job_data_all_pages, RESULT_JSON_FILE)\n    await context.close()\n    await browser.close()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5789621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee97f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c05f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a47e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180634f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9705e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}